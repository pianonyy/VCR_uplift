{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Siamese_networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2SJ-abn1cFt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.utils.extmath import stable_cumsum\n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "\n",
        "def uplift_curve(y_true, uplift, treatment):\n",
        "    \n",
        "\n",
        "    check_consistent_length(y_true, uplift, treatment)\n",
        "    \n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    desc_score_indices = np.argsort(uplift, kind=\"mergesort\")[::-1]\n",
        "    y_true, uplift, treatment = y_true[desc_score_indices], uplift[desc_score_indices], treatment[desc_score_indices]\n",
        "\n",
        "    y_true_ctrl, y_true_trmnt = y_true.copy(), y_true.copy()\n",
        "\n",
        "    y_true_ctrl[treatment == 1] = 0\n",
        "    y_true_trmnt[treatment == 0] = 0\n",
        "\n",
        "    distinct_value_indices = np.where(np.diff(uplift))[0]\n",
        "    threshold_indices = np.r_[distinct_value_indices, uplift.size - 1]\n",
        "\n",
        "    num_trmnt = stable_cumsum(treatment)[threshold_indices]\n",
        "    y_trmnt = stable_cumsum(y_true_trmnt)[threshold_indices]\n",
        "\n",
        "    num_all = threshold_indices + 1\n",
        "\n",
        "    num_ctrl = num_all - num_trmnt\n",
        "    y_ctrl = stable_cumsum(y_true_ctrl)[threshold_indices]\n",
        "\n",
        "    curve_values = (np.divide(y_trmnt, num_trmnt, out=np.zeros_like(y_trmnt), where=num_trmnt != 0) -\n",
        "                    np.divide(y_ctrl, num_ctrl, out=np.zeros_like(y_ctrl), where=num_ctrl != 0)) * num_all\n",
        "\n",
        "    if num_all.size == 0 or curve_values[0] != 0 or num_all[0] != 0:\n",
        "        # Add an extra threshold position if necessary\n",
        "        # to make sure that the curve starts at (0, 0)\n",
        "        num_all = np.r_[0, num_all]\n",
        "        curve_values = np.r_[0, curve_values]\n",
        "\n",
        "    return num_all, curve_values\n",
        "\n",
        "\n",
        "def perfect_uplift_curve(y_true, treatment):\n",
        "   \n",
        "\n",
        "    check_consistent_length(y_true, treatment)\n",
        "    \n",
        "    y_true, treatment = np.array(y_true), np.array(treatment)\n",
        "\n",
        "    cr_num = np.sum((y_true == 1) & (treatment == 0))  # Control Responders\n",
        "    tn_num = np.sum((y_true == 0) & (treatment == 1))  # Treated Non-Responders\n",
        "\n",
        "    # express an ideal uplift curve through y_true and treatment\n",
        "    summand = y_true if cr_num > tn_num else treatment\n",
        "    perfect_uplift = 2 * (y_true == treatment) + summand\n",
        "\n",
        "    return uplift_curve(y_true, perfect_uplift, treatment)\n",
        "\n",
        "\n",
        "def uplift_auc_score(y_true, uplift, treatment):\n",
        "   \n",
        "\n",
        "    check_consistent_length(y_true, uplift, treatment)\n",
        "    \n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    x_actual, y_actual = uplift_curve(y_true, uplift, treatment)\n",
        "    x_perfect, y_perfect = perfect_uplift_curve(y_true, treatment)\n",
        "    x_baseline, y_baseline = np.array([0, x_perfect[-1]]), np.array([0, y_perfect[-1]])\n",
        "\n",
        "    auc_score_baseline = auc(x_baseline, y_baseline)\n",
        "    auc_score_perfect = auc(x_perfect, y_perfect) - auc_score_baseline\n",
        "    auc_score_actual = auc(x_actual, y_actual) - auc_score_baseline\n",
        "\n",
        "    return auc_score_actual / auc_score_perfect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsvphRCT4Xr_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.utils.extmath import stable_cumsum\n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPX_jtIXxsxR",
        "outputId": "7c8a018a-4f09-40d0-e0a0-f405e6d6c153"
      },
      "source": [
        "!git clone https://github.com/pianonyy/UPLIFT_modeling.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'UPLIFT_modeling'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (221/221), done.\u001b[K\n",
            "remote: Total 567 (delta 153), reused 192 (delta 74), pack-reused 266\u001b[K\n",
            "Receiving objects: 100% (567/567), 13.66 MiB | 13.55 MiB/s, done.\n",
            "Resolving deltas: 100% (265/265), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvZ2ZOU9xxYf",
        "outputId": "dbf3e719-0b90-4d8a-ff9f-160ed6208d55"
      },
      "source": [
        "!pip install -e UPLIFT_modeling/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/UPLIFT_modeling\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from uplift==0.1) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from uplift==0.1) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from uplift==0.1) (0.29.21)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from uplift==0.1) (1.0.1)\n",
            "Installing collected packages: uplift\n",
            "  Running setup.py develop for uplift\n",
            "Successfully installed uplift\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSBY7CdGF-U"
      },
      "source": [
        "import logging\n",
        "from os.path import join as pjoin\n",
        "from typing import Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "N_PURCHASES_ROWS = None\n",
        "DATA_PATH = '/content/drive/MyDrive/' \n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_clients() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'clients.csv'),\n",
        "        parse_dates=['first_issue_date', 'first_redeem_date'],\n",
        "    )\n",
        "\n",
        "\n",
        "def prepare_clients() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing clients...')\n",
        "    clients = load_clients()\n",
        "    client_encoder = LabelEncoder()\n",
        "    clients['client_id'] = client_encoder.fit_transform(clients['client_id'])\n",
        "    logger.info('Clients are ready')\n",
        "    return clients, client_encoder\n",
        "\n",
        "\n",
        "def load_products() -> pd.DataFrame:\n",
        "    return pd.read_csv(pjoin(DATA_PATH, 'products.csv'))\n",
        "\n",
        "\n",
        "def prepare_products() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing products...')\n",
        "    products = load_products()\n",
        "    product_encoder = LabelEncoder()\n",
        "    products['product_id'] = product_encoder. \\\n",
        "        fit_transform(products['product_id'])\n",
        "\n",
        "    products.fillna(-1, inplace=True)\n",
        "\n",
        "    for col in [\n",
        "        'level_1', 'level_2', 'level_3', 'level_4',\n",
        "        'segment_id', 'brand_id', 'vendor_id',\n",
        "    ]:\n",
        "        products[col] = LabelEncoder().fit_transform(products[col].astype(str))\n",
        "    logger.info('Products are ready')\n",
        "    return products, product_encoder\n",
        "\n",
        "\n",
        "def load_purchases() -> pd.DataFrame:\n",
        "    logger.info('Loading purchases...')\n",
        "    purchases = pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'purchases.csv'),\n",
        "        nrows=N_PURCHASES_ROWS,\n",
        "    )\n",
        "    logger.info('Purchases are loaded')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def prepare_purchases(\n",
        "        client_encoder: LabelEncoder,\n",
        "        product_encoder: LabelEncoder,\n",
        ") -> pd.DataFrame:\n",
        "    logger.info('Preparing purchases...')\n",
        "    purchases = load_purchases()\n",
        "\n",
        "    logger.info('Handling n/a values...')\n",
        "    purchases.dropna(\n",
        "        subset=['client_id', 'product_id'],\n",
        "        how='any',\n",
        "        inplace=True,\n",
        "    )\n",
        "    purchases.fillna(-1, inplace=True)\n",
        "\n",
        "    logger.info('Label encoding...')\n",
        "    purchases['client_id'] = client_encoder.transform(purchases['client_id'])\n",
        "    purchases['product_id'] = product_encoder.transform(purchases['product_id'])\n",
        "    for col in ['transaction_id', 'store_id']:\n",
        "        purchases[col] = LabelEncoder(). \\\n",
        "            fit_transform(purchases[col].astype(str))\n",
        "\n",
        "    logger.info('Date and time conversion...')\n",
        "    purchases['datetime'] = pd.to_datetime(\n",
        "        purchases['transaction_datetime'],\n",
        "        format='%Y-%m-%d %H:%M:%S',\n",
        "    )\n",
        "    purchases.drop(columns=['transaction_datetime'], inplace=True)\n",
        "\n",
        "    logger.info('Purchases are ready')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def load_train() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_train.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n",
        "\n",
        "\n",
        "def load_test() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_test.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8JO4biyK97B",
        "outputId": "f997239b-757e-452f-b7b6-e7d13a23f431"
      },
      "source": [
        "!unzip /content/drive/MyDrive/features.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/features.zip\n",
            "  inflating: features.pkl            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et_g8OCuS1Fi",
        "outputId": "073fc430-6b56-41e9-ded8-313977f6f1ab"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 7.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219253 sha256=7245a3b28da818a3793dc58eb09f00bdd082b379d5dbbce1e3c31f8ab8e38b30\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV94X1S55omZ",
        "outputId": "3763c3d1-617a-43f1-8eb0-9750d76f2199"
      },
      "source": [
        "import pickle5\n",
        "\n",
        "RANDOM_STATE = 12\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = load_train()\n",
        "indices_train = train.index\n",
        "with open('features.pkl', 'rb') as f:\n",
        "        features: pd.DataFrame = pickle5.load(f)\n",
        "\n",
        "features.set_index('client_id', inplace=True)\n",
        "X_train = features.loc[indices_train, :]\n",
        "\n",
        "\n",
        "\n",
        "treatment_train = train.loc[indices_train, 'treatment_flg'].values\n",
        "y_train = train.loc[indices_train, 'target'].values\n",
        "\n",
        "X_train['treatment'] = treatment_train\n",
        "X_train['target'] = y_train\n",
        "\n",
        "X_train.loc[(X_train['target'] == 1) & (X_train['treatment'] == 1),'Z_trans'] = 2\n",
        "X_train.loc[(X_train['target'] == 1) & (X_train['treatment'] == 0),'Z_trans'] =  -2\n",
        "X_train.loc[X_train['Z_trans'].isnull(), 'Z_trans'] = 0\n",
        "\n",
        "print(X_train[['Z_trans','treatment','target']])\n",
        "\n",
        "\n",
        "\n",
        "indices_learn, indices_valid = train_test_split(\n",
        "        X_train.index,\n",
        "        test_size=0.3,\n",
        "        random_state = RANDOM_STATE,\n",
        ")\n",
        "\n",
        "all = X_train.copy()\n",
        "X_train =all.loc[indices_learn,]\n",
        "X_test = all.loc[indices_valid,]\n",
        "\n",
        "\n",
        "treatment_train = X_train['treatment']\n",
        "y_train = X_train['target']\n",
        "Z_trans_train = X_train['Z_trans']\n",
        "\n",
        "treatment_test = X_test['treatment']\n",
        "y_test = X_test['target']\n",
        "Z_trans_test = X_test['Z_trans']\n",
        "\n",
        "\n",
        "X_train=X_train.drop('Z_trans',axis = 1)\n",
        "X_train=X_train.drop('target',axis = 1)\n",
        "X_train=X_train.drop('treatment',axis = 1)\n",
        "\n",
        "X_test=X_test.drop('Z_trans',axis = 1)\n",
        "X_test=X_test.drop('target',axis = 1)\n",
        "X_test=X_test.drop('treatment',axis = 1)\n",
        "\n",
        "\n",
        "# print(treatment_test)\n",
        "# print(treatment_train)\n",
        "\n",
        "print(\"propensity score in train:\", treatment_train[treatment_train == 1].shape[0] / treatment_train.shape[0])\n",
        "print(\"propensity score in test:\", treatment_test[treatment_test == 1].shape[0] / treatment_test.shape[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Z_trans  treatment  target\n",
            "client_id                             \n",
            "000012768d     -2.0          0       1\n",
            "000036f903      2.0          1       1\n",
            "00010925a5      2.0          1       1\n",
            "0001f552b0      2.0          1       1\n",
            "00020e7b18      2.0          1       1\n",
            "...             ...        ...     ...\n",
            "fffcb91f10      0.0          1       0\n",
            "fffd5cd0c6      2.0          1       1\n",
            "fffd63dfe3      2.0          1       1\n",
            "fffd8c9d7d      0.0          1       0\n",
            "fffe0abb97      0.0          0       0\n",
            "\n",
            "[200035 rows x 3 columns]\n",
            "propensity score in train: 0.49853596526309774\n",
            "propensity score in test: 0.5027911549549249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD8glUCpg9aw",
        "outputId": "130e2953-dd96-4f9d-d941-5639886b0ffc"
      },
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\r\n",
        "# from sklearn import preprocessing\r\n",
        "\r\n",
        "# Z_train_dummies = pd.get_dummies(Z_trans_train)\r\n",
        "# Z_test_dummies = pd.get_dummies(Z_trans_test)\r\n",
        "\r\n",
        "# print(Z_train_dummies)\r\n",
        "# print(Z_test_dummies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            -2.0   0.0   2.0\n",
            "client_id                   \n",
            "5803624422     0     1     0\n",
            "20b7b05f7d     1     0     0\n",
            "0c10e0113f     0     1     0\n",
            "1761677f2d     0     0     1\n",
            "aa188a0008     1     0     0\n",
            "...          ...   ...   ...\n",
            "4ef8dd16ad     0     0     1\n",
            "a54f58238b     0     0     1\n",
            "2e7eeaca71     0     1     0\n",
            "332b911361     0     0     1\n",
            "c13eba9d88     0     1     0\n",
            "\n",
            "[140024 rows x 3 columns]\n",
            "            -2.0   0.0   2.0\n",
            "client_id                   \n",
            "353f2648f3     0     1     0\n",
            "f0d6002166     0     1     0\n",
            "af4f3039fe     0     0     1\n",
            "34b4ce6c2a     0     0     1\n",
            "7046ea76d3     0     0     1\n",
            "...          ...   ...   ...\n",
            "d5c9592f5f     1     0     0\n",
            "555d2436d3     1     0     0\n",
            "bc21e85e6e     1     0     0\n",
            "aa4d24e82f     0     1     0\n",
            "ad18c83a2e     0     0     1\n",
            "\n",
            "[60011 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEkkrFERTR6O",
        "outputId": "3e2429cc-cb12-467e-e68c-779fd27e801f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scaler = StandardScaler(with_std = True, with_mean = True)\n",
        "\n",
        "X_train_0 = X_train.copy()\n",
        "# X_train_0['treatment'] = 0\n",
        "\n",
        "X_train_1 = X_train.copy()\n",
        "# X_train_1['treatment'] = 1\n",
        "\n",
        "X_train_1 = X_train_1.astype('float32')\n",
        "X_train_1 = X_train_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_1 = scaler.fit_transform(X_train_1)\n",
        "\n",
        "X_train_0 = X_train_0.astype('float32')\n",
        "X_train_0 = X_train_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_0 = scaler.fit_transform(X_train_0)\n",
        "\n",
        "\n",
        "X_test_0 = X_test.copy()\n",
        "# X_test_0['treatment'] = 0\n",
        "\n",
        "X_test_1 = X_test.copy()\n",
        "# X_test_1['treatment'] = 1\n",
        "\n",
        "X_test_1 = X_test_1.astype('float32')\n",
        "X_test_1 = X_test_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_1 = scaler.fit_transform(X_test_1)\n",
        "\n",
        "X_test_0 = X_test_0.astype('float32')\n",
        "X_test_0 = X_test_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_0 = scaler.fit_transform(X_test_0)\n",
        "\n",
        "X_test_0 = np.c_[ X_test_0, np.zeros(X_test_0.shape[0]) ]\n",
        "X_test_1 = np.c_[ X_test_1, np.ones(X_test_1.shape[0]) ] \n",
        "\n",
        "X_train_0 = np.c_[ X_train_0, np.zeros(X_train_0.shape[0]) ]\n",
        "X_train_1 = np.c_[ X_train_1, np.ones(X_train_1.shape[0]) ]\n",
        "\n",
        "# X_train_0 = np.c_[ X_train_0, treatment_train ]\n",
        "# X_train_1 = np.c_[ X_train_1, treatment_train ]\n",
        "\n",
        "# X_train_0 = np.c_[ X_train_0, y_train ]\n",
        "# X_train_1 = np.c_[ X_train_1, y_train ]\n",
        "\n",
        "# X_train_0 = np.c_[ X_train_0, Z_trans_train ]\n",
        "# X_train_1 = np.c_[ X_train_1, Z_trans_train ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_0, \"size = \", type(X_train_0))\n",
        "print(X_train_1, \"size = \", X_train_1.shape)\n",
        "\n",
        "print(X_test_0, \"size = \", X_test_0.shape)\n",
        "print(X_test_1, \"size = \", X_test_1.shape)\n",
        "\n",
        "\n",
        "# np.savetxt('train_0.txt', X_train_0, delimiter=',')\n",
        "# np.savetxt('train_1.txt', X_train_1, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
            "  sqr = np.multiply(arr, arr, out=arr)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
            "  sqr = np.multiply(arr, arr, out=arr)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
            "  sqr = np.multiply(arr, arr, out=arr)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
            "  sqr = np.multiply(arr, arr, out=arr)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-0.44834757 -0.76292139  1.07323432 ... -0.63726395 -0.76138622\n",
            "   0.        ]\n",
            " [ 2.23041248 -0.76292139 -0.93176299 ...  0.31792825  0.18582669\n",
            "   0.        ]\n",
            " [-0.44834757 -0.76292139  1.07323432 ... -0.12555383 -0.28777978\n",
            "   0.        ]\n",
            " ...\n",
            " [-0.44834757 -0.76292139  1.07323432 ...  0.52261227  0.7024883\n",
            "   0.        ]\n",
            " [-0.44834757  1.31075096 -0.93176299 ... -0.70549196 -0.67527598\n",
            "   0.        ]\n",
            " [-0.44834757 -0.76292139  1.07323432 ...  0.59084028  1.00387418\n",
            "   0.        ]] size =  <class 'numpy.ndarray'>\n",
            "[[-0.44834757 -0.76292139  1.07323432 ... -0.63726395 -0.76138622\n",
            "   1.        ]\n",
            " [ 2.23041248 -0.76292139 -0.93176299 ...  0.31792825  0.18582669\n",
            "   1.        ]\n",
            " [-0.44834757 -0.76292139  1.07323432 ... -0.12555383 -0.28777978\n",
            "   1.        ]\n",
            " ...\n",
            " [-0.44834757 -0.76292139  1.07323432 ...  0.52261227  0.7024883\n",
            "   1.        ]\n",
            " [-0.44834757  1.31075096 -0.93176299 ... -0.70549196 -0.67527598\n",
            "   1.        ]\n",
            " [-0.44834757 -0.76292139  1.07323432 ...  0.59084028  1.00387418\n",
            "   1.        ]] size =  (140024, 334)\n",
            "[[-0.44917509 -0.76564211  1.07793105 ... -1.14727926 -1.23297393\n",
            "   0.        ]\n",
            " [-0.44917509  1.30609334 -0.92770314 ... -0.77350336 -0.80430514\n",
            "   0.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ... -1.28319776 -1.27584076\n",
            "   0.        ]\n",
            " ...\n",
            " [-0.44917509  1.30609334 -0.92770314 ...  0.21190564  0.22449981\n",
            "   0.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ...  0.07598715  0.05303232\n",
            "   0.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ... -0.29778868 -0.37563643\n",
            "   0.        ]] size =  (60011, 334)\n",
            "[[-0.44917509 -0.76564211  1.07793105 ... -1.14727926 -1.23297393\n",
            "   1.        ]\n",
            " [-0.44917509  1.30609334 -0.92770314 ... -0.77350336 -0.80430514\n",
            "   1.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ... -1.28319776 -1.27584076\n",
            "   1.        ]\n",
            " ...\n",
            " [-0.44917509  1.30609334 -0.92770314 ...  0.21190564  0.22449981\n",
            "   1.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ...  0.07598715  0.05303232\n",
            "   1.        ]\n",
            " [-0.44917509 -0.76564211  1.07793105 ... -0.29778868 -0.37563643\n",
            "   1.        ]] size =  (60011, 334)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H9vuwkoJpZ8",
        "outputId": "1f49b6d1-14a2-4f5b-ebba-b5aa79cb07cb"
      },
      "source": [
        "!7z a -tzip -mx5 -r0 /content/archive.zip train_0.txt train_1.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Open archive: /content/archive.zip\n",
            "--\n",
            "Path = /content/archive.zip\n",
            "Type = zip\n",
            "Physical Size = 732823300\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan \b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b2 files, 2416192878 bytes (2305 MiB)\n",
            "\n",
            "Updating archive: /content/archive.zip\n",
            "\n",
            "Items to compress: 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 2 U train_1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Files read from disk: 2\n",
            "Archive size: 689590120 bytes (658 MiB)\n",
            "Everything is Ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCR8UhfJt3eI"
      },
      "source": [
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data_0,X_data_1,Z_trans,treatment, y_data):\n",
        "        self.X_data_0 = X_data_0\n",
        "        self.X_data_1 = X_data_1\n",
        "        self.Z_trans = Z_trans\n",
        "        self.treatment = treatment\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data_0[index], self.X_data_1[index],self.Z_trans[index], self.treatment[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data_0)\n",
        "\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(X_train_0),torch.FloatTensor(X_train_1),torch.FloatTensor(Z_trans_train),torch.FloatTensor(treatment_train), \n",
        "                       torch.FloatTensor(y_train))\n",
        "## test data    \n",
        "\n",
        "class testData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data_0,X_data_1,Z_trans,treatment,y_data):\n",
        "        self.X_data_0 = X_data_0\n",
        "        self.X_data_1 = X_data_1\n",
        "        self.Z_trans = Z_trans\n",
        "        self.treatment = treatment\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data_0[index], self.X_data_1[index],self.Z_trans[index], self.treatment[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data_0)\n",
        "    \n",
        "\n",
        "test_data = testData(torch.FloatTensor(X_test_0),torch.FloatTensor(X_test_1), torch.FloatTensor(Z_trans_test),torch.FloatTensor(treatment_test), \n",
        "                       torch.FloatTensor(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QFze6m8QwSX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "\n",
        "  \n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "\n",
        "\n",
        "\n",
        "def plot_qini_curve(y_reactions, uplift_score, treatment, random=True, perfect=True):\n",
        "    \"\"\"Plot Qini curves from predictions.\"\"\"\n",
        "   \n",
        "    check_consistent_length(y_reactions, uplift_score, treatment)\n",
        "    y_reactions, uplift_score, treatment = np.array(y_reactions), np.array(uplift_score), np.array(treatment)\n",
        "\n",
        "   \n",
        "\n",
        "    x_actual, y_actual = qini_curve(y_reactions, uplift_score, treatment)\n",
        "\n",
        "    pylab.plot(x_actual, y_actual, label='Our model', color='green')\n",
        "    if random:\n",
        "        x_baseline, y_baseline = x_actual, x_actual * y_actual[-1] / len(y_reactions)\n",
        "        pylab.plot(x_baseline, y_baseline, label='Random model', color='black')\n",
        "        \n",
        "\n",
        "    if perfect:\n",
        "        x_perfect, y_perfect = perfect_qini_curve(y_reactions, treatment)\n",
        "        # print(\"1 point\", x_perfect[1], y_perfect[1])\n",
        "        # print(\"2 point\", x_perfect[2], y_perfect[2])\n",
        "        # print(\"3 point\", x_perfect[3], y_perfect[3])\n",
        "        pylab.plot(x_perfect, y_perfect, label='Perfect model', color='Red')\n",
        "        \n",
        "    #pylab.fill_between(x_perfect, y_baseline, y_perfect, color=\"blue\")\n",
        "    pylab.grid(True)\n",
        "    pylab.xlabel('Treat num')\n",
        "    pylab.ylabel('Uplift reactions')\n",
        "    pylab.title('Qini curve')\n",
        "    pylab.legend(loc='lower right')\n",
        "    return pylab\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpZxmbiJjDFZ"
      },
      "source": [
        "cross entropy with Z_dummies ( не работает )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDc2stYwjCzO"
      },
      "source": [
        "# import torch\r\n",
        "# from torch.autograd import Variable\r\n",
        "# import torch.nn as nn\r\n",
        "# import torch.nn.functional as F\r\n",
        "\r\n",
        "# import random\r\n",
        "# import numpy as np\r\n",
        "# import torch.optim as optim\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "# from statistics import mean\r\n",
        "\r\n",
        "# batch_size = 35006   # Number of samples in each batch\r\n",
        "# batch_size_test=7 #7\r\n",
        "# epoch_num = 19  # Number of epochs to train the network  to do try more epochs\r\n",
        "# lr = 0.001        # Learning rate\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# class Model(nn.Module):\r\n",
        "#     def __init__(self):\r\n",
        "#         super(Model, self).__init__()\r\n",
        "#         self.fc1 = nn.Linear(334, 200)\r\n",
        "#         self.fc2 = nn.Linear(200, 100)\r\n",
        "#         self.fc3 = nn.Linear(100, 3)\r\n",
        "\r\n",
        "#     def forward(self, x):\r\n",
        "        \r\n",
        "#         x = F.relu(self.fc1(x))\r\n",
        "#         x = F.relu(self.fc2(x))\r\n",
        "#         x = self.fc3(x)\r\n",
        "#         m = nn.Softmax()\r\n",
        "#         return m(x)\r\n",
        "        \r\n",
        "\r\n",
        "# model = Model()\r\n",
        "# alpha = 1.0\r\n",
        "\r\n",
        "# # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "# # print(device)\r\n",
        "# # model.to(device)\r\n",
        "# # print(model)\r\n",
        "\r\n",
        "\r\n",
        "# # #convert to torch structure\r\n",
        "# # X_test_1_tensor = torch.FloatTensor(X_test_1) \r\n",
        "# # X_test_0_tensor = torch.FloatTensor(X_test_0)\r\n",
        "\r\n",
        "\r\n",
        "# # #convert to torch structure\r\n",
        "# # treatment_test = treatment_test.to_numpy()\r\n",
        "# # treatment_test = torch.from_numpy(treatment_test).int()\r\n",
        "# # treatment_test = Variable(treatment_test)\r\n",
        "\r\n",
        "\r\n",
        "# # #convert to torch structure\r\n",
        "# # y_test = y_test.to_numpy()\r\n",
        "# # y_test = torch.from_numpy(y_test).float()\r\n",
        "# # y_test  = Variable(y_test)\r\n",
        "\r\n",
        "\r\n",
        "# # #convert to torch structure\r\n",
        "# # Z_trans_test = Z_trans_test.to_numpy()\r\n",
        "# # Z_trans_test = torch.from_numpy(Z_trans_test).float()\r\n",
        "# # Z_trans_test = Variable(Z_trans_test)\r\n",
        "\r\n",
        "\r\n",
        "# #init loaders\r\n",
        "# train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\r\n",
        "# test_loader = DataLoader(dataset=test_data, batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# # define the loss (criterion) and create an optimizer\r\n",
        "# optimizer = optim.Adam(model.parameters())\r\n",
        "\r\n",
        "# # define lists of losses to store\r\n",
        "# all_losses  = []\r\n",
        "# test_losses = []\r\n",
        "# min_losses = []\r\n",
        "\r\n",
        "\r\n",
        "# model.train()\r\n",
        "# # epochs loop\r\n",
        "# for ep in range(epoch_num):  \r\n",
        "#     print(\".......................... epoch =\",ep,\"..........................\")\r\n",
        "#     batch_loss = []\r\n",
        "#     # batches loop\r\n",
        "#     for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in train_loader:\r\n",
        "       \r\n",
        "       \r\n",
        "        \r\n",
        "#         batch_1_feat = X_batch_1\r\n",
        "#         batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "#         batch_label = y_batch\r\n",
        "#         batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "#         optimizer.zero_grad()\r\n",
        "#         # Forward pass (predict)\r\n",
        "#         mu_1_target_class = model(batch_1_feat)\r\n",
        "#         mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "#         #convert to torch structure\r\n",
        "#         treatment_batch = treatment_batch\r\n",
        "       \r\n",
        "\r\n",
        "#         # mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "#         # mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "     \r\n",
        "\r\n",
        "\r\n",
        "       \r\n",
        "#         #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "#         # uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "       \r\n",
        "\r\n",
        "       \r\n",
        "        \r\n",
        "        \r\n",
        "#         #declare losses\r\n",
        "#         loss_cross = nn.CrossEntropyLoss()\r\n",
        "      \r\n",
        "\r\n",
        "#         #implements uplift_predicted = mu_1 - mu_0\r\n",
        "#         uplift_pred = mu_1_target_class - mu_0_target_class \r\n",
        "        \r\n",
        "#         # Z_trans_train = torch.Tensor(Z_batch) \r\n",
        "#         # Z_dummies = torch.nn.functional.one_hot(Z_trans_train.to(torch.int64), num_classes = 3)\r\n",
        "\r\n",
        "#         Z_trans_train = Z_batch.to(torch.int64)\r\n",
        "#         print(\"Z_train\",Z_trans_train)\r\n",
        "\r\n",
        "#         pred_uplift = mu_1_target_class - mu_0_target_class\r\n",
        "#         print(\"uplift_pred\", pred_uplift)\r\n",
        "\r\n",
        "       \r\n",
        "        \r\n",
        "\r\n",
        "#         sum_of_losses = torch.mean(  loss_cross(mu_1_target_class-mu_0_target_class,Z_trans_train) )\r\n",
        "#         # print(loss_contrastive)\r\n",
        "#         batch_loss.append(sum_of_losses)\r\n",
        "#         # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "\r\n",
        "        \r\n",
        "#         # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "#         # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "#         # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "#         # Backward pass and updates\r\n",
        "#         sum_of_losses.backward()                     # calculate the gradients\r\n",
        "#         optimizer.step()                    # update the weights\r\n",
        "#         # i += batch_size\r\n",
        "#         #end for !!!!!!!!!!!!!!!!!!!\r\n",
        "\r\n",
        "#     # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "#     # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "#     batch_loss  = list(batch_loss)\r\n",
        "#     all_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "\r\n",
        "#     # # #work with test dataset\r\n",
        "#     # print('work with test dataset')\r\n",
        "#     # batch_loss = []\r\n",
        "#     # for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in test_loader:\r\n",
        "        \r\n",
        "       \r\n",
        "        \r\n",
        "#     #     batch_1_feat = X_batch_1\r\n",
        "#     #     batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "#     #     batch_label = y_batch\r\n",
        "#     #     batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "#     #     optimizer.zero_grad()\r\n",
        "#     #     # Forward pass (predict)\r\n",
        "#     #     mu_1_target_class = model(batch_1_feat)\r\n",
        "#     #     mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "       \r\n",
        "       \r\n",
        "\r\n",
        "#     #     # mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "#     #     # mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "#     #     # print(\"mu_0\", mu_0_target_class)\r\n",
        "#     #     # print(\"mu_1\", mu_1_target_class)\r\n",
        "\r\n",
        "#     #     ones = np.ones(shape = batch_size_test)\r\n",
        "#     #     ones = torch.from_numpy(ones).float()\r\n",
        "        \r\n",
        "     \r\n",
        "#     #     #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "#     #     uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "#     #     #declare losses\r\n",
        "#     #     loss_cross = nn.BCELoss(reduction = 'mean')\r\n",
        "#     #     loss_MSE = nn.MSELoss()\r\n",
        "\r\n",
        "#     #     #implements uplift_predicted = mu_1 - mu_0\r\n",
        "#     #     uplift_pred = mu_1_target_class - mu_0_target_class   \r\n",
        "\r\n",
        "#     #     sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\r\n",
        "       \r\n",
        "#     #     batch_loss.append(sum_of_losses)\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "#     #     # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "#     #     # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "#     #     # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "#         #end for\r\n",
        "#     # batch_loss  = list(batch_loss)\r\n",
        "#     # test_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "   \r\n",
        "\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# plt.plot(all_losses, color='green',label='train')\r\n",
        "# plt.title('train vs test')\r\n",
        "# plt.xlabel('epoch_num')\r\n",
        "# plt.ylabel('loss sum')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# # plt.plot(test_losses, color='blue',label='test')\r\n",
        "# # plt.legend()\r\n",
        "\r\n",
        "\r\n",
        "# # plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltIEM_3G_6AV"
      },
      "source": [
        "4 эпохи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "ro0CHMRE_7k_",
        "outputId": "51f9d6ca-d055-4673-e446-9792376614ef"
      },
      "source": [
        "import torch\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import torch.optim as optim\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from statistics import mean\r\n",
        "\r\n",
        "batch_size = 23 # 250-500  # Number of samples in each batch to do(/9)\r\n",
        "batch_size_test=60011  \r\n",
        "\r\n",
        "\r\n",
        "epoch_num = 4  # Number of epochs to train the network\r\n",
        "lr = 0.001        # Learning rate\r\n",
        "\r\n",
        "\r\n",
        "#140000 - train\r\n",
        "#60011 - test\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(334, 200)\r\n",
        "        self.fc2 = nn.Linear(200, 100)\r\n",
        "        self.fc3 = nn.Linear(100, 1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        m = nn.Sigmoid()\r\n",
        "        return m(x)\r\n",
        "\r\n",
        "# class Model(nn.Module):\r\n",
        "#     def __init__(self):\r\n",
        "#         super(Model, self).__init__()\r\n",
        "        \r\n",
        "#         self.fc1 = nn.Linear(334, 290)\r\n",
        "#         self.fc2 = nn.Linear(290, 210)\r\n",
        "#         self.fc3 = nn.Linear(210, 170)\r\n",
        "#         self.fc4 = nn.Linear(170, 130)\r\n",
        "#         self.fc5 = nn.Linear(130, 90)\r\n",
        "#         self.fc6 = nn.Linear(90, 10)\r\n",
        "#         self.fc7 = nn.Linear(10, 1)\r\n",
        "\r\n",
        "\r\n",
        "#         # # ...\r\n",
        "#         # self.fc2 = nn.Linear(200, 100)\r\n",
        "\r\n",
        "\r\n",
        "#         # self.fc3 = nn.Linear(100, 1) # conv1d??\r\n",
        "\r\n",
        "#     def forward(self, x):\r\n",
        "        \r\n",
        "#         x = F.relu(self.fc1(x))  #leaky_relu ???\r\n",
        "#         x = F.relu(self.fc2(x))\r\n",
        "#         x = F.relu(self.fc3(x))  #leaky_relu ???\r\n",
        "#         x = F.relu(self.fc4(x))\r\n",
        "#         x = F.relu(self.fc5(x))  #leaky_relu ???\r\n",
        "#         x = F.relu(self.fc6(x))\r\n",
        "#         x = self.fc7(x)\r\n",
        "#         m = nn.Sigmoid()\r\n",
        "#         return m(x)\r\n",
        "        \r\n",
        "\r\n",
        "# class Model(nn.Module):\r\n",
        "#     def __init__(self): \r\n",
        "#         super(Model, self).__init__()\r\n",
        "#         self.classifier = nn.Sequential(\r\n",
        "#             nn.Linear(334, 200),\r\n",
        "#             nn.BatchNorm1d(200), #applying batch norm\r\n",
        "#             nn.ReLU(),\r\n",
        "#             nn.Linear(200, 100),\r\n",
        "#             nn.BatchNorm1d(100),\r\n",
        "#             nn.ReLU(),\r\n",
        "#             nn.Linear(100, 1)\r\n",
        "#         )\r\n",
        "             \r\n",
        "#     def forward(self, x):\r\n",
        "#         x = x.view(x.size(0), -1)\r\n",
        "#         x = self.classifier(x)\r\n",
        "#         m = nn.Sigmoid()\r\n",
        "#         return m(x)\r\n",
        "#         # return x\r\n",
        "\r\n",
        "model = Model()\r\n",
        "alpha = 0.3\r\n",
        "\r\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "# print(device)\r\n",
        "# model.to(device)\r\n",
        "# print(model)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \r\n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# treatment_test = treatment_test.to_numpy()\r\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\r\n",
        "# treatment_test = Variable(treatment_test)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# y_test = y_test.to_numpy()\r\n",
        "# y_test = torch.from_numpy(y_test).float()\r\n",
        "# y_test  = Variable(y_test)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\r\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\r\n",
        "# Z_trans_test = Variable(Z_trans_test)\r\n",
        "\r\n",
        "\r\n",
        "#init loaders\r\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# define the loss (criterion) and create an optimizer\r\n",
        "optimizer = optim.Adam(model.parameters(),lr = lr)\r\n",
        "\r\n",
        "# sgd??   \r\n",
        "\r\n",
        "# define lists of losses to store\r\n",
        "all_losses  = []\r\n",
        "test_losses = []\r\n",
        "min_losses = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# epochs loop\r\n",
        "for ep in range(epoch_num):  \r\n",
        "    model.train()\r\n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\r\n",
        "    batch_loss = []\r\n",
        "    # batches loop\r\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in train_loader:\r\n",
        "       \r\n",
        "       \r\n",
        "        \r\n",
        "        batch_1_feat = X_batch_1\r\n",
        "        batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "        batch_label = y_batch\r\n",
        "        batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        # Forward pass (predict)\r\n",
        "        mu_1_target_class = model(batch_1_feat)\r\n",
        "        mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "        #convert to torch structure\r\n",
        "        treatment_batch = treatment_batch\r\n",
        "       \r\n",
        "\r\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "        # print(\"mu_0\", mu_0_target_class)\r\n",
        "        # print(\"mu_1\", mu_1_target_class)\r\n",
        "\r\n",
        "        ones = np.ones(shape = batch_size)\r\n",
        "        ones = torch.from_numpy(ones).float()\r\n",
        "        \r\n",
        "\r\n",
        "       \r\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "       \r\n",
        "\r\n",
        "       \r\n",
        "        \r\n",
        "        \r\n",
        "        #declare losses\r\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\r\n",
        "        loss_MSE = nn.MSELoss()\r\n",
        "\r\n",
        "        #implements uplift_predicted = mu_1 - mu_0\r\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \r\n",
        "        \r\n",
        "        \r\n",
        "        # print(\"uplift_pred\", uplift_pred)\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\r\n",
        "        # print(loss_contrastive)\r\n",
        "        batch_loss.append(sum_of_losses)\r\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "\r\n",
        "        \r\n",
        "        # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "        # Backward pass and updates\r\n",
        "        sum_of_losses.backward()                     # calculate the gradients\r\n",
        "        optimizer.step()                    # update the weights\r\n",
        "        # i += batch_size\r\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\r\n",
        "\r\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "    # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "    batch_loss  = list(batch_loss)\r\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "\r\n",
        "    # #work with test dataset\r\n",
        "    print('work with test dataset')\r\n",
        "    batch_loss = []\r\n",
        "\r\n",
        "   \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in test_loader:\r\n",
        "        \r\n",
        "       \r\n",
        "        \r\n",
        "        batch_1_feat = X_batch_1\r\n",
        "        batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "        batch_label = y_batch\r\n",
        "        batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "        # optimizer.zero_grad()\r\n",
        "        # Forward pass (predict)\r\n",
        "        mu_1_target_class = model(batch_1_feat)\r\n",
        "        mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "       \r\n",
        "       \r\n",
        "\r\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "        # print(\"mu_0\", mu_0_target_class)\r\n",
        "        # print(\"mu_1\", mu_1_target_class)\r\n",
        "\r\n",
        "        ones = np.ones(shape = batch_size_test)\r\n",
        "        ones = torch.from_numpy(ones).float()\r\n",
        "        \r\n",
        "     \r\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "        #declare losses\r\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\r\n",
        "        loss_MSE = nn.MSELoss()\r\n",
        "\r\n",
        "        #implements uplift_predicted = mu_1 - mu_0\r\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class   \r\n",
        "        \r\n",
        "\r\n",
        "        # scatter plot for mse parametres to do !!!\r\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\r\n",
        "       \r\n",
        "        batch_loss.append(sum_of_losses)\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "        # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "    #     #end for\r\n",
        "    batch_loss  = list(batch_loss)\r\n",
        "    test_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "   \r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(all_losses, color='green',label='train')\r\n",
        "plt.title('train vs test')\r\n",
        "plt.xlabel('epoch_num')\r\n",
        "plt.ylabel('loss sum')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "plt.plot(test_losses, color='blue',label='test')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......................... epoch = 0 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 1 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 2 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 3 ..........................\n",
            "work with test dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxf52gsqYnIF"
      },
      "source": [
        "neural network with dataloader (то, что работает ) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "D26MHedEYmpz",
        "outputId": "e3bb3d1b-0c0b-4bcc-83a8-36bff4455344"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 23 # 250-500  # Number of samples in each batch to do(/9)\n",
        "batch_size_test=60011  \n",
        "\n",
        "\n",
        "epoch_num = 4  # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "\n",
        "\n",
        "#140000 - train\n",
        "#60011 - test\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        m = nn.Sigmoid()\n",
        "        return m(x)\n",
        "\n",
        "# class Model(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Model, self).__init__()\n",
        "        \n",
        "#         self.fc1 = nn.Linear(334, 290)\n",
        "#         self.fc2 = nn.Linear(290, 210)\n",
        "#         self.fc3 = nn.Linear(210, 170)\n",
        "#         self.fc4 = nn.Linear(170, 130)\n",
        "#         self.fc5 = nn.Linear(130, 90)\n",
        "#         self.fc6 = nn.Linear(90, 10)\n",
        "#         self.fc7 = nn.Linear(10, 1)\n",
        "\n",
        "\n",
        "#         # # ...\n",
        "#         # self.fc2 = nn.Linear(200, 100)\n",
        "\n",
        "\n",
        "#         # self.fc3 = nn.Linear(100, 1) # conv1d??\n",
        "\n",
        "#     def forward(self, x):\n",
        "        \n",
        "#         x = F.relu(self.fc1(x))  #leaky_relu ???\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = F.relu(self.fc3(x))  #leaky_relu ???\n",
        "#         x = F.relu(self.fc4(x))\n",
        "#         x = F.relu(self.fc5(x))  #leaky_relu ???\n",
        "#         x = F.relu(self.fc6(x))\n",
        "#         x = self.fc7(x)\n",
        "#         m = nn.Sigmoid()\n",
        "#         return m(x)\n",
        "        \n",
        "\n",
        "# class Model(nn.Module):\n",
        "#     def __init__(self): \n",
        "#         super(Model, self).__init__()\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(334, 200),\n",
        "#             nn.BatchNorm1d(200), #applying batch norm\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(200, 100),\n",
        "#             nn.BatchNorm1d(100),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(100, 1)\n",
        "#         )\n",
        "             \n",
        "#     def forward(self, x):\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.classifier(x)\n",
        "#         m = nn.Sigmoid()\n",
        "#         return m(x)\n",
        "#         # return x\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.3\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# model.to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test).float()\n",
        "# y_test  = Variable(y_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "\n",
        "#init loaders\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size_test, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr = lr)\n",
        "\n",
        "# sgd??   \n",
        "\n",
        "# define lists of losses to store\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "\n",
        "\n",
        "# epochs loop\n",
        "for ep in range(epoch_num):  \n",
        "    model.train()\n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\n",
        "    batch_loss = []\n",
        "    # batches loop\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in train_loader:\n",
        "       \n",
        "       \n",
        "        \n",
        "        batch_1_feat = X_batch_1\n",
        "        batch_0_feat = X_batch_0\n",
        "        \n",
        "        batch_label = y_batch\n",
        "        batch_Z_trans = Z_batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "        #convert to torch structure\n",
        "        treatment_batch = treatment_batch\n",
        "       \n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "\n",
        "       \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "       \n",
        "\n",
        "       \n",
        "        \n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "        \n",
        "        # print(\"uplift_pred\", uplift_pred)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        # print(loss_contrastive)\n",
        "        batch_loss.append(sum_of_losses)\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        # Backward pass and updates\n",
        "        sum_of_losses.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        # i += batch_size\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "    # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "\n",
        "    # #work with test dataset\n",
        "    print('work with test dataset')\n",
        "    batch_loss = []\n",
        "\n",
        "   \n",
        "    model.eval()\n",
        "    \n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in test_loader:\n",
        "        \n",
        "       \n",
        "        \n",
        "        batch_1_feat = X_batch_1\n",
        "        batch_0_feat = X_batch_0\n",
        "        \n",
        "        batch_label = y_batch\n",
        "        batch_Z_trans = Z_batch\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "       \n",
        "       \n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size_test)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "     \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class   \n",
        "        \n",
        "\n",
        "        # scatter plot for mse parametres to do !!!\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "       \n",
        "        batch_loss.append(sum_of_losses)\n",
        "        \n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        \n",
        "        \n",
        "    #     #end for\n",
        "    batch_loss  = list(batch_loss)\n",
        "    test_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_losses, color='green',label='train')\n",
        "plt.title('train vs test')\n",
        "plt.xlabel('epoch_num')\n",
        "plt.ylabel('loss sum')\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(test_losses, color='blue',label='test')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......................... epoch = 0 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 1 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 2 ..........................\n",
            "work with test dataset\n",
            ".......................... epoch = 3 ..........................\n",
            "work with test dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrwCYhMD614w",
        "outputId": "c0e3c12a-c6ce-4e1f-ed3d-db960f905689"
      },
      "source": [
        "from UPLIFT_modeling.uplift.metrics import Kendall_rank_correlation, qini_auc_score, uplift_at_k\r\n",
        "\r\n",
        "all_res_uplift = []\r\n",
        "all_res_auqc = []\r\n",
        "all_res_rank_correlation = []\r\n",
        "all_res_auuc = []\r\n",
        "\r\n",
        "for j in range( 1, 101, 1):\r\n",
        "\r\n",
        "    #logger.info(f\"Random state =:{j}\")\r\n",
        "    RANDOM_STATE = j\r\n",
        "    indices_learn_new, indices_valid_new = train_test_split(\r\n",
        "        indices_valid,\r\n",
        "        test_size=0.35,\r\n",
        "        random_state = RANDOM_STATE,\r\n",
        "    )\r\n",
        "   \r\n",
        "\r\n",
        "    X_valid = features.loc[indices_valid_new, :]\r\n",
        "    treatment_valid = train.loc[indices_valid_new, 'treatment_flg'].values\r\n",
        "    target_valid = train.loc[indices_valid_new, 'target'].values\r\n",
        "\r\n",
        "    X_valid_0 = X_valid.copy()\r\n",
        "    X_valid_1 = X_valid.copy()\r\n",
        "\r\n",
        "    X_valid_1 = X_valid_1.astype('float32')\r\n",
        "    X_valid_1 = X_valid_1.replace([np.inf, -np.inf], np.nan).fillna(0)\r\n",
        "    X_valid_1 = scaler.fit_transform(X_valid_1)\r\n",
        "\r\n",
        "    X_valid_0 = X_valid_0.astype('float32')\r\n",
        "    X_valid_0 = X_valid_0.replace([np.inf, -np.inf], np.nan).fillna(0)\r\n",
        "    X_valid_0 = scaler.fit_transform(X_valid_0)\r\n",
        "\r\n",
        "    X_valid_0 = np.c_[ X_valid_0, np.zeros(X_valid_0.shape[0]) ]\r\n",
        "    X_valid_1 = np.c_[ X_valid_1, np.ones(X_valid_1.shape[0]) ] \r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    X_valid_1 = torch.FloatTensor(X_valid_1)\r\n",
        "    X_valid_0 = torch.FloatTensor(X_valid_0)\r\n",
        "    \r\n",
        "    mu_1 = model(X_valid_1)\r\n",
        "    mu_0 = model(X_valid_0)\r\n",
        "    valid_pred = mu_1-mu_0\r\n",
        "    \r\n",
        "    valid_pred = valid_pred.detach().numpy()\r\n",
        "    valid_pred = valid_pred.reshape((-1,)) \r\n",
        "  \r\n",
        "    valid_pred = pd.Series(valid_pred, index = indices_valid_new)\r\n",
        "    \r\n",
        "    # valid_pred = clf.predict(X_valid)\r\n",
        "    AUQC = qini_auc_score(target_valid, valid_pred, treatment_valid)\r\n",
        "   \r\n",
        "    valid_scores = uplift_at_k(target_valid, valid_pred, treatment_valid)\r\n",
        "    tau, p_value = Kendall_rank_correlation(target_valid, valid_pred, treatment_valid)\r\n",
        "    auuc = uplift_auc_score(target_valid, valid_pred, treatment_valid)\r\n",
        "    \r\n",
        "    all_res_uplift.append(valid_scores)\r\n",
        "    all_res_auqc.append(AUQC)\r\n",
        "    all_res_rank_correlation.append(tau)\r\n",
        "    all_res_auuc.append(auuc)\r\n",
        "    \r\n",
        "print('Число замеров', j)\r\n",
        "print('AUQC: mean: ', np.mean(all_res_auqc),\"| std: \", np.std(all_res_auqc, ddof=1))\r\n",
        "print('uplift30%: mean: ', np.mean(all_res_uplift),\"| std: \",np.std(all_res_uplift, ddof=1))\r\n",
        "print('Kendall_rank_correlation: mean: ',np.mean(all_res_rank_correlation), \"| std: \", np.std(all_res_rank_correlation,ddof=1))\r\n",
        "print('AUUC: mean: ',np.mean(all_res_auuc), \"| std: \", np.std(all_res_auuc,ddof=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6888888888888888 with p_value =  0.00468694885361552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6444444444444444 with p_value =  0.009148478835978836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.24444444444444444 with p_value =  0.38071979717813054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6888888888888888 with p_value =  0.00468694885361552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.24444444444444444 with p_value =  0.38071979717813054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6444444444444444 with p_value =  0.009148478835978836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  -0.1111111111111111 with p_value =  0.7274895282186948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.24444444444444444 with p_value =  0.38071979717813054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.1111111111111111 with p_value =  0.7274895282186948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6888888888888888 with p_value =  0.00468694885361552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.24444444444444444 with p_value =  0.38071979717813054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.7333333333333333 with p_value =  0.002212852733686067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.24444444444444444 with p_value =  0.38071979717813054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4666666666666666 with p_value =  0.07255015432098766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5111111111111111 with p_value =  0.04662257495590829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.911111111111111 with p_value =  2.9761904761904762e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.28888888888888886 with p_value =  0.2912483465608466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.19999999999999998 with p_value =  0.4843127204585538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.4222222222222222 with p_value =  0.10831349206349207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.6 with p_value =  0.016666115520282188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.3333333333333333 with p_value =  0.21637345679012346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.37777777777777777 with p_value =  0.1557418430335097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Kendal uplift rank correlation =  0.5555555555555555 with p_value =  0.02860945767195767\n",
            "Число замеров 100\n",
            "AUQC: mean:  723797.8087892927 | std:  340631.7282155845\n",
            "uplift30%: mean:  0.05274711713281108 | std:  0.011127808525418314\n",
            "Kendall_rank_correlation: mean:  0.42933333333333334 | std:  0.1517041245785407\n",
            "AUUC: mean:  0.01195040683235274 | std:  0.005543724239963879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te0hK3Mv3Hkh"
      },
      "source": [
        "def uplift_at_k(y_target, prediction_score, treatment, rate=0.3):\r\n",
        "\r\n",
        "    check_consistent_length(y_target, prediction_score, treatment)\r\n",
        "    prediction_score = np.array(prediction_score)\r\n",
        "    order = np.argsort(prediction_score, kind='mergesort')[::-1]\r\n",
        "    # order = np.argsort(-prediction_score)\r\n",
        "    treatment_n = int((treatment == 1).sum() * rate)\r\n",
        "    treatment_p = y_target[order][treatment[order] == 1][:treatment_n].mean()\r\n",
        "    control_n = int((treatment == 0).sum() * rate)\r\n",
        "    control_p = y_target[order][treatment[order] == 0][:control_n].mean()\r\n",
        "    score = treatment_p - control_p\r\n",
        "    return score\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrXSfMTiVDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54356bff-76be-4da7-8ddb-1c787c430542"
      },
      "source": [
        "X_test_1 = torch.FloatTensor(X_test_1)\n",
        "X_test_0 = torch.FloatTensor(X_test_0)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "mu_1 = model(X_test_1)\n",
        "mu_0 = model(X_test_0)\n",
        "\n",
        "pred = mu_1-mu_0\n",
        "\n",
        "# print(pred)\n",
        "\n",
        "# print(torch.min(pred))\n",
        "\n",
        "pred = pred.detach().numpy()\n",
        "\n",
        "# print(pred)\n",
        "# print(y_test)\n",
        "\n",
        "pred = pred.reshape((-1,)) \n",
        "# print(pred)\n",
        "  \n",
        "pred = pd.Series(pred, index = y_test.index)\n",
        "\n",
        "print(\"qini_auc_score\",qini_auc_score(y_test, pred, treatment_test))\n",
        "\n",
        "\n",
        "print(\"uplift_at_30%\",uplift_at_k(y_test, pred, treatment_test))\n",
        "# print(y_train[0:10])\n",
        "# print(\"------------------\")\n",
        "# print(treatment_train[0:10])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "qini_auc_score 8800997.231153477\n",
            "uplift_at_30% 0.06049210261626348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ZYSyNf7N6WVp",
        "outputId": "7e3ffc7d-041e-4a20-c8dd-cb6d74f36d8a"
      },
      "source": [
        "from UPLIFT_modeling.uplift.metrics import qini_curve\r\n",
        "x,y = qini_curve(y_test, pred, treatment_test)\r\n",
        "plt.plot(x, y)\r\n",
        "plt.plot([ x[0], x[len(x)-1] ], [ y[0], y[len(y) - 1  ]] )\r\n",
        "plt.title('alpha=0.3 - лучший результат')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'alpha=0.3 - лучший результат')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "embVSUfReUlH",
        "outputId": "4d0b5e10-9a5f-45a4-9148-0182af2c86de"
      },
      "source": [
        "from UPLIFT_modeling.uplift.vizualization import plot_qini_curve\r\n",
        "plot_qini_curve(y_test, pred, treatment_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0aef1749b352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mUPLIFT_modeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muplift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvizualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_qini_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_qini_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3pG4SIWxshm"
      },
      "source": [
        "6912405.144559544 alpha = 0.2\r\n",
        "\r\n",
        "alpha = 0.0  0\r\n",
        "\r\n",
        "alpha = 0.1 663*10^4   0.048\r\n",
        "\r\n",
        "alpha = 0.2   760*10^4\r\n",
        "\r\n",
        "alpha = 0.3    804*10^4   0.053\r\n",
        "\r\n",
        "alpha = 0.4   605*10^4  0.049\r\n",
        "\r\n",
        "alpha = 0.5   688*10^4 0.054\r\n",
        "\r\n",
        "alpha = 0.6   635*10^4 0.047\r\n",
        "\r\n",
        "alpha = 0.7  728*10^4  0.057\r\n",
        "\r\n",
        "alpha = 0.8  379*10^4 0.051\r\n",
        "\r\n",
        "alpha = 0.9 365*10^4 0.044\r\n",
        "\r\n",
        "alpha = 1.0 145*10^4  0.042\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "EUxzIshC0lpL",
        "outputId": "f261aa71-3b5d-45f5-c4cc-be88483cf0b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "plt.plot(['0.0','0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9','1.0'], [0, 663, 760, 804, 605,688,635,728,379,365,145])\r\n",
        "plt.title('Сравнение вкладов каждого из лосс')\r\n",
        "plt.xlabel('alpha')\r\n",
        "plt.ylabel('площадь под qini кривой (auqc)')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPMlwkGzDX2m"
      },
      "source": [
        "X_train_1 = torch.FloatTensor(X_train_1)\r\n",
        "X_train_0 = torch.FloatTensor(X_train_0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.eval()\r\n",
        "\r\n",
        "mu_1 = model(X_train_1)\r\n",
        "mu_0 = model(X_train_0)\r\n",
        "\r\n",
        "pred = mu_1-mu_0\r\n",
        "\r\n",
        "print(pred)\r\n",
        "\r\n",
        "pred = pred.detach().numpy()\r\n",
        "print(qini_auc_score(y_train, pred, treatment_train))\r\n",
        "\r\n",
        "# print(y_train[0:10])\r\n",
        "# print(\"------------------\")\r\n",
        "# print(treatment_train[0:10])\r\n",
        "# plot_qini_curve(y_train, pred, treatment_train)\r\n",
        "\r\n",
        "# tm_uplift_at_k = uplift_at_k(y_true=y_train, uplift=pred, treatment=treatment_train,\r\n",
        "#                              strategy='overall', k=0.3)\r\n",
        "\r\n",
        "print(tm_uplift_at_k)\r\n",
        "\r\n",
        "# print(torch.max(pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4cLfVvZHIL"
      },
      "source": [
        "proposing network with sigmoid\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3IxOEpZZEXc"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 35006   # Number of samples in each batch\n",
        "epoch_num = 40   # Number of epochs to train the network\n",
        "lr = 0.0001        # Learning rate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        m = nn.Sigmoid()\n",
        "        return m(x)\n",
        "        \n",
        "\n",
        "model = Model()\n",
        "alpha = 0.8\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# model.to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test).float()\n",
        "# y_test  = Variable(y_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "\n",
        "#init loaders\n",
        "# train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# define lists of losses to store\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "\n",
        "model.train()\n",
        "# epochs loop\n",
        "for ep in range(epoch_num):  \n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    # batches loop\n",
        "    for batch_n in range(batch_per_ep):  \n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "        #convert to torch structure\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "\n",
        "       \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, shape = (-1,))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "        \n",
        "        # print(\"uplift_pred\", uplift_pred)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        # print(loss_contrastive)\n",
        "        batch_loss.append(sum_of_losses)\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        # Backward pass and updates\n",
        "        sum_of_losses.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "    print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "\n",
        "    # #work with test dataset\n",
        "\n",
        "    # mu_1 = model(X_test_1_tensor)\n",
        "    # mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    # mu_1_target_class = mu_1\n",
        "    # mu_0_target_class = mu_0\n",
        "\n",
        "    # ones = np.ones(shape = X_test_1.shape[0])\n",
        "    # ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    # #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    # uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    # mu_0_target_class = torch.reshape(mu_0_target_class, (-1,))\n",
        "    # mu_1_target_class = torch.reshape(mu_1_target_class, (-1,))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    # #declare losses\n",
        "    # loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "    # loss_MSE = nn.MSELoss()\n",
        "\n",
        "    # #implements uplift_predicted = mu_1 - mu_0\n",
        "    # uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    # sum_of_losses =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test) )\n",
        "    # test_losses.append(sum_of_losses)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_losses, color='green')\n",
        "plt.title('sum_of_losses')\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(test_losses, color='blue')\n",
        "# plt.title('sum_of_losses')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpsL9Oq8PKVN"
      },
      "source": [
        "X_train_1 = torch.FloatTensor(X_train_1)\n",
        "X_train_0 = torch.FloatTensor(X_train_0)\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "mu_1 = model(X_train_1)\n",
        "mu_0 = model(X_train_0)\n",
        "\n",
        "pred = mu_1-mu_0\n",
        "print(qini_auc_score(y_train, pred.detach().numpy(), treatment_train))\n",
        "\n",
        "print(pred)\n",
        "print(torch.max(pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLXT97dapoc"
      },
      "source": [
        "example of siamese network!!!!\n",
        "2 out, softmax two classification\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzEBJvdtZdi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "eb431ec9-56cd-47a7-d456-eb70af269b10"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 12      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))    # F.log_softmax = log( exp(x_i) / exp(x).sum() )\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.3\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "X_test_1_tensor = torch.FloatTensor(X_test_1)\n",
        "X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "treatment_test = treatment_test.to_numpy()\n",
        "treatment_test = torch.from_numpy(treatment_test).int()\n",
        "treatment_test = Variable(treatment_test)\n",
        "\n",
        "y_test = y_test.to_numpy()\n",
        "y_test = torch.from_numpy(y_test ).float()\n",
        "y_test  = Variable(y_test )\n",
        "\n",
        "\n",
        "#convert to torch structure\n",
        "Z_trans_test = Z_trans_test.to_numpy()\n",
        "Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_contrastive = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        \n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "    #work with test dataset\n",
        "\n",
        "    mu_1 = model(X_test_1_tensor)\n",
        "    mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    mu_1_target_class = mu_1[:,1]\n",
        "    mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "    ones = np.ones(shape = X_test_1.shape[0])\n",
        "    ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    mu_0_target_class = torch.reshape(mu_0_target_class, (X_test_1.shape[0],1))\n",
        "    mu_1_target_class = torch.reshape(mu_1_target_class, (X_test_1.shape[0],1))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    #declare losses\n",
        "    loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "    loss_MSE = nn.MSELoss()\n",
        "\n",
        "    #implements uplift_predicted = mu_1 - mu_0\n",
        "    uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test))\n",
        "    test_losses.append(loss_contrastive)\n",
        "    \n",
        "    # print(qini_auc_score(y_test.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_test.cpu().detach().numpy() ))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses,color='blue')\n",
        "# plt.plot(test_losses, color='green')\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(all_losses,color='blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........................epoch = 0 ..........................\n",
            "..........................epoch = 1 ..........................\n",
            "..........................epoch = 2 ..........................\n",
            "..........................epoch = 3 ..........................\n",
            "..........................epoch = 4 ..........................\n",
            "..........................epoch = 5 ..........................\n",
            "..........................epoch = 6 ..........................\n",
            "..........................epoch = 7 ..........................\n",
            "..........................epoch = 8 ..........................\n",
            "..........................epoch = 9 ..........................\n",
            "..........................epoch = 10 ..........................\n",
            "..........................epoch = 11 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATb0lEQVR4nO3df7DddX3n8efLBH/RVYJJMyEBwxZqS9nV6m1krbVZaW2w1tCdFcEfZFxGOrvaFeus0N2OWHQ76GgX3VGnVChxrFBEVujWihlapV3FcmNZDFBMpMYEAgkGqIAuUN77x/nc9hhCbnLvSU5yP8/HzJnzPe/v53zO+3vJvM73fM73XlJVSJL68LRxNyBJOnAMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj60iwl+YUkd4y7D2lvGPoamyRvSDKZ5KEk25L8eZKXj2Dey5K8fxQ9PsX8leS4qcdV9VdV9YL98DrvTfLpUc+rvhn6GoskvwVcBPwesBg4Bvg4sPoAvPb8/f0a0sHK0NcBl+S5wAXA26rq6qp6uKoeq6o/rar/0sY8I8lFSe5ut4uSPKPtW5lka5J3JdnePiW8pe07G3gj8O72CeJPW/07Sc5NcgvwcJL5Sc5L8u0k309yW5JfH+rxuCRfSfJgkvuS/Emr39CG/N82/+un+mn7z01y1S7H+5EkH5069iSXtJ7vSvL+JPNm8DN8bZJbkzyQ5MtJfnpo37lt7u8nuSPJya2+on2y+ock9yb5/X19Xc0BVeXN2wG9AauAx4H5exhzAXAj8OPAIuCrwPvavpXt+RcAhwGvBh4BFrT9lwHv32W+7wA3A0cDz2q11wFHMTj5eT3wMLCk7bsc+G9t3zOBlw/NVcBxQ49XAlvb9vNbL/+iPZ4HbANOao//F/AHwOHt2P4G+I2n+Bm8F/j0buo/2Xr95Xb87wY2AU8HXgBsAY5qY5cDP9G2vwa8uW3/2FRP3vq6eaavcXgecF9VPb6HMW8ELqiq7VW1A/hd4M1D+x9r+x+rqi8ADzEIvD35aFVtqaofAFTVZ6vq7qp6oqr+BNgIrBia//kMwvOHVfXXe3NgVbUZ+AYw9anhlcAjVXVjksUM3qDOqcGnm+3A/wBO35u5h7we+LOqWldVjwEfAp4FvAz4R+AZwAlJDquq71TVt4eO6bgkC6vqoaq6cR9fV3OAoa9x+B6wcJq19aOAzUOPN7faP82xy5vGIwzOXvdky/CDJGcmubktkTwAnAgsbLvfDQT4m7aM8h+mmXvYZ4Az2vYb2mMYvIkcBmwbes0/YHDGvy9+5GdTVU8wOLalVbUJOIfBp4TtSa5IMvVzO4vBp4S/S3JTktfs4+tqDjD0NQ5fA/4fcOoextzNICSnHNNqe+Op/nTsP9WTPB/4Q+DtwPOq6ghgA4Ogp6ruqaq3VtVRwG8AHx++YmcanwVWJlnG4Ix/KvS3MDjuhVV1RLs9p6p+Zi/nnfIjP5skYbBsdVfr/TNV9fI2poAPtPrGqjqDwZvMB4Crkhy+j6+tQ5yhrwOuqh4E3gN8LMmpSZ6d5LAkpyT5YBt2OfA7SRYlWdjG7+3li/cC/3KaMYczCMQdAO2L4BOndiZ5XQttgPvb2Cf2Zv62HPVl4I+Av6+q21t9G/Al4MNJnpPkaUl+Iskv7qHPpyV55tDtGcCVwK8mOTnJYcC7GLyZfDXJC5K8so37IfCDqb6TvCnJovbJ4IE2/xNPfknNZYa+xqKqPgz8FvA7DIJ3C4Oz7s+3Ie8HJoFbgG8yWCff22vvL2Gwpv1Aks/vbkBV3QZ8mMGnjnuBfwX8n6EhPwd8PclDwLXAO6rqzrbvvcDaNv9pT9HDZ4Bf4p/P8qecyeAL19sYvJlcBSzZw7GcwSC4p27frqo7gDcB/xO4D/g14Neq6lEG6/kXtvo9DM7qf7vNtQq4tR3TR4DTp77fUD9S5f9ERZJ64Zm+JHXE0Jekjhj6ktQRQ1+SOnJQ/+GphQsX1vLly8fdhiQdUtavX39fVS3a3b6DOvSXL1/O5OTkuNuQpENKks1Ptc/lHUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRaUM/yaVJtifZMFQ7Msm6JBvb/YKhfSuT3Jzk1iRfGaqvSnJHkk1Jzhv9oUiSprM3Z/qXAat2qZ0HXF9VxwPXt8ckOQL4OPDaqvoZ4HWtPg/4GHAKcAJwRpITRnEAkqS9N23oV9UNwM5dyquBtW17LXBq234DcHVVfbc9d3urrwA2VdWdVfUocEWbQ5J0AM10TX9xVW1r2/cAi9v2TwILknw5yfokZ7b6UmDL0PO3ttqTJDk7yWSSyR07dsywPUnS7syf7QRVVUlqaL6XACcDzwK+luTGfZzvYuBigImJiZpmuCRpH8w09O9NsqSqtiVZAkwt42wFvldVDwMPJ7kBeGGrHz30/GXAXTNtWpI0MzNd3rkWWNO21wDXtO1rgJcnmZ/k2cBLgduBm4Djkxyb5OnA6W0OSdIBNO2ZfpLLgZXAwiRbgfOBC4Erk5wFbAZOA6iq25N8EbgFeAL4ZFVtaPO8HbgOmAdcWlW3jv5wJEl7kqqDd9l8YmKiJicnx92GJB1Skqyvqond7fM3ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHpg39JJcm2Z5kw1DtyCTrkmxs9wt2ec7PJXk8yb8fqq1p4zcmWTPaw5Ak7Y29OdO/DFi1S+084PqqOh64vj0GIMk84APAl4ZqRwLnAy8FVgDn7/pGIUna/6YN/aq6Adi5S3k1sLZtrwVOHdr3m8DngO1DtV8B1lXVzqq6H1jHk99IJEn72UzX9BdX1ba2fQ+wGCDJUuDXgU/sMn4psGXo8dZWe5IkZyeZTDK5Y8eOGbYnSdqdWX+RW1UFVHt4EXBuVT0xi/kurqqJqppYtGjRbNuTJA2ZP8Pn3ZtkSVVtS7KEf17KmQCuSAKwEHh1kseBu4CVQ89fBnx5hq8tSZqhmZ7pXwtMXYGzBrgGoKqOrarlVbUcuAr4T1X1eeA64FVJFrQvcF/VapKkA2jaM/0klzM4S1+YZCuDq3AuBK5MchawGThtT3NU1c4k7wNuaqULqmrXL4clSftZBkvyB6eJiYmanJwcdxuSdEhJsr6qJna3z9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkfmj7uB/eWcc+Dmm8fdhSTNzIteBBddNPp5pz3TT3Jpku1JNgzVjkyyLsnGdr+g1d+Y5JYk30zy1SQvHHrOqiR3JNmU5LzRH4okaTqpqj0PSF4BPAR8qqpObLUPAjur6sIW4Auq6twkLwNur6r7k5wCvLeqXppkHvAt4JeBrcBNwBlVddueXntiYqImJydne4yS1JUk66tqYnf7pj3Tr6obgJ27lFcDa9v2WuDUNvarVXV/q98ILGvbK4BNVXVnVT0KXNHmkCQdQDP9IndxVW1r2/cAi3cz5izgz9v2UmDL0L6trfYkSc5OMplkcseOHTNsT5K0O7O+eqcG60M/skaU5N8yCP1zZzDfxVU1UVUTixYtmm17kqQhMw39e5MsAWj326d2JPnXwCeB1VX1vVa+Czh66PnLWk2SdADNNPSvBda07TXANQBJjgGuBt5cVd8aGn8TcHySY5M8HTi9zSFJOoCmvU4/yeXASmBhkq3A+cCFwJVJzgI2A6e14e8Bngd8PAnA422p5vEkbweuA+YBl1bVraM+GEnSnk17yeY4ecmmJO27WV2yKUmaOwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOTBv6SS5Nsj3JhqHakUnWJdnY7he0epJ8NMmmJLckefHQc9a08RuTrNk/hyNJ2pO9OdO/DFi1S+084PqqOh64vj0GOAU4vt3OBj4BgzcJ4HzgpcAK4PypNwpJ0oEzbehX1Q3Azl3Kq4G1bXstcOpQ/VM1cCNwRJIlwK8A66pqZ1XdD6zjyW8kkqT9bKZr+ouralvbvgdY3LaXAluGxm1ttaeqP0mSs5NMJpncsWPHDNuTJO3OrL/IraoCagS9TM13cVVNVNXEokWLRjWtJImZh/69bdmGdr+91e8Cjh4at6zVnqouSTqAZhr61wJTV+CsAa4Zqp/ZruI5CXiwLQNdB7wqyYL2Be6rWk2SdADNn25AksuBlcDCJFsZXIVzIXBlkrOAzcBpbfgXgFcDm4BHgLcAVNXOJO8DbmrjLqiqXb8cliTtZxksyR+cJiYmanJyctxtSNIhJcn6qprY3T5/I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZFahn+QdSTYkuTXJOa32oiQ3Jrk5yWSSFa2eJB9NsinJLUlePIoDkCTtvRmHfpITgbcCK4AXAq9JchzwQeB3q+pFwHvaY4BTgOPb7WzgE7PoW5I0A7M50/9p4OtV9UhVPQ58Bfh3QAHPaWOeC9zdtlcDn6qBG4EjkiyZxetLkvbR/Fk8dwPw35M8D/gB8GpgEjgHuC7Jhxi8qbysjV8KbBl6/tZW2zY8aZKzGXwS4JhjjplFe5KkXc34TL+qbgc+AHwJ+CJwM/CPwH8E3llVRwPvBC7Zx3kvrqqJqppYtGjRTNuTJO3GrL7IrapLquolVfUK4H7gW8Aa4Oo25LMM1vwB7gKOHnr6slaTJB0gs71658fb/TEM1vM/w2AN/xfbkFcCG9v2tcCZ7Sqek4AHq2obkqQDZjZr+gCfa2v6jwFvq6oHkrwV+EiS+cAPaevzwBcYrPtvAh4B3jLL15Yk7aNZhX5V/cJuan8NvGQ39QLeNpvXkyTNjr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOpKqGncPTynJDmDzLKZYCNw3onYONh7boWsuH5/HdnB4flUt2t2Ogzr0ZyvJZFVNjLuP/cFjO3TN5ePz2A5+Lu9IUkcMfUnqyFwP/YvH3cB+5LEduuby8XlsB7k5vaYvSfpRc/1MX5I0xNCXpI7MydBPsirJHUk2JTlv3P2MUpKjk/xlktuS3JrkHePuadSSzEvyt0n+97h7GaUkRyS5KsnfJbk9yb8Zd0+jlOSd7d/khiSXJ3nmuHuaqSSXJtmeZMNQ7cgk65JsbPcLxtnjTM250E8yD/gYcApwAnBGkhPG29VIPQ68q6pOAE4C3jbHjg/gHcDt425iP/gI8MWq+inghcyhY0yyFPjPwERVnQjMA04fb1ezchmwapfaecD1VXU8cH17fMiZc6EPrAA2VdWdVfUocAWwesw9jUxVbauqb7Tt7zMIjqXj7Wp0kiwDfhX45Lh7GaUkzwVeAVwCUFWPVtUD4+1q5OYDz0oyH3g2cPeY+5mxqroB2LlLeTWwtm2vBU49oE2NyFwM/aXAlqHHW5lDoTgsyXLgZ4Gvj7eTkboIeDfwxLgbGbFjgR3AH7Wlq08mOXzcTY1KVd0FfAj4LrANeLCqvjTerkZucVVta9v3AIvH2cxMzcXQ70KSHwM+B5xTVf8w7n5GIclrgO1VtX7cvewH84EXA5+oqp8FHuYQXR7Ynba+vZrBm9tRwOFJ3jTervafGlzrfkhe7z4XQ/8u4Oihx8tabc5IchiDwP/jqrp63P2M0M8Dr03yHQbLcq9M8unxtjQyW4GtVTX1qewqBm8Cc8UvAX9fVTuq6jHgauBlY+5p1O5NsgSg3W8fcz8zMhdD/ybg+CTHJnk6gy+Trh1zTyOTJAzWhW+vqt8fdz+jVFW/XVXLqmo5g/9uf1FVc+JssaruAbYkeUErnQzcNsaWRu27wElJnt3+jZ7MHPqiurkWWNO21wDXjLGXGZs/7gZGraoeT/J24DoGVxBcWlW3jrmtUfp54M3AN5Pc3Gr/taq+MMaetHd+E/jjdjJyJ/CWMfczMlX19SRXAd9gcIXZ33II/9mCJJcDK4GFSbYC5wMXAlcmOYvBn3w/bXwdzpx/hkGSOjIXl3ckSU/B0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kd+f82Q+4m3g6ppQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oqmylLF-06iI",
        "outputId": "89f35b83-2fb7-489b-eaee-19aa4493c160"
      },
      "source": [
        "\r\n",
        "from UPLIFT_modeling.uplift.metrics import uplift_at_k,qini_auc_score\r\n",
        "\r\n",
        "X_test_1 = torch.FloatTensor(X_test_1)\r\n",
        "X_test_0 = torch.FloatTensor(X_test_0)\r\n",
        "\r\n",
        "model.eval()\r\n",
        "\r\n",
        "mu_1 = model(X_test_1)\r\n",
        "mu_0 = model(X_test_0)\r\n",
        "\r\n",
        "pred = mu_1-mu_0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "pred = pred.detach().numpy()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# pred = pred.reshape((-1,)) \r\n",
        "\r\n",
        "  \r\n",
        "# pred = pd.Series(pred, index = y_test.index)\r\n",
        "\r\n",
        "\r\n",
        "print(y_test.shape)\r\n",
        "print(pred.shape)\r\n",
        "print(treatment_test.shape)\r\n",
        "\r\n",
        "print(\"qini_auc_score\",qini_auc_score(y_test, pred[:,0], treatment_test))\r\n",
        "\r\n",
        "\r\n",
        "print(\"uplift_at_30%\",uplift_at_k(y_test, pred, treatment_test))\r\n",
        "# print(y_train[0:10])\r\n",
        "# print(\"------------------\")\r\n",
        "# print(treatment_train[0:10])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60011])\n",
            "(60011, 2)\n",
            "torch.Size([60011])\n",
            "qini_auc_score 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-cb1d815d83b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uplift_at_30%\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muplift_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m# print(y_train[0:10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# print(\"------------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/UPLIFT_modeling/uplift/metrics/ranking.py\u001b[0m in \u001b[0;36muplift_at_k\u001b[0;34m(y_target, prediction_score, treatment, rate)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# order = np.argsort(-prediction_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mtreatment_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreatment\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mtreatment_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtreatment_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mcontrol_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreatment\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mcontrol_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcontrol_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOQ_S5FGayLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "a56cba6c-6741-491b-b3fb-46a2a3df771d"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 20      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.8\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "all_losses  = []\n",
        "min_losses =[]\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "        loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "\n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses)\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-35d23d29b3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mZ_trans_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_trans_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mall_losses\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mmin_losses\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: reshape(): argument 'input' (position 1) must be Tensor, not Series"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCOiW7WcMNUc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses[:210000])\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}